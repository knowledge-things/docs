Paper 
===============

.. toctree::
    CVPR2022 æœ‰ä»€ä¹ˆå€¼å¾—å…³æ³¨çš„è®ºæ–‡ ? <https://www.zhihu.com/question/517340666/answer/2381304399>
    Collections ä¼šè®®è®ºæ–‡é›†å’ŒæœŸåˆŠ <paper_collections.md>
    LORA <https://arxiv.org/pdf/2106.09685.pdf>
    Computer Vision in the Wild (CVinW) <https://github.com/Computer-Vision-in-the-Wild/CVinW_Readings>
    ä¼šè®®è®ºæ–‡é›†å’ŒæœŸåˆŠ <https://www.jarvis73.com/collection/#conferences>
    paper-computer-vision <https://github.com/haozhangcn/paper-computer-vision/blob/0aa051573f2e6293e72ce1ddcfb7bef34d64e052/2022/202206/20220614.md>
    CVPR 2023 è®ºæ–‡å’Œå¼€æºé¡¹ç›®åˆé›†(Papers with Code) <https://github.com/amusi/CVPR2023-Papers-with-Code>
    Image Captioning <https://paperswithcode.com/task/image-captioning#task-home>

Formwork
===========

.. toctree::
    kornia <https://github.com/kornia/kornia>


playground
================

.. toctree::
    EditAnything <https://github.com/sail-sg/EditAnything>
    diffusionbee <https://github.com/divamgupta/diffusionbee-stable-diffusion-ui>
    Discover AI Technologies <https://lablab.ai/tech>
    ä»»åŠ¡é©±åŠ¨çš„è‡ªæ²»ä»£ç† <https://github.com/yoheinakajima/babyagi>
    ä½¿ç”¨æ¥åœ°DINOè¿›è¡Œè‡ªåŠ¨å›¾åƒæ ‡è®° <https://www.kdnuggets.com/2023/05/automatic-image-labeling-grounding-dino.html>
    Awesome colab notebooks collection <https://github.com/amrzv/awesome-colab-notebooks.git>
    replicate playground Collections <https://replicate.com/collections/super-resolution>
    A Simple Object Detection App Built Using Streamlit And OpenCV. <https://blog.devgenius.io/a-simple-object-detection-app-built-using-streamlit-and-opencv-4365c90f293c>

Learn  website
================

.. toctree::
    roboflow notebooks <https://github.com/roboflow/notebooks>
    Prompt Engineering Guide <https://www.promptingguide.ai/models/flan>
    langchain <https://python.langchain.com/en/latest/modules/prompts/prompt_templates/getting_started.html>
    Awesome-Anything <https://github.com/VainF/Awesome-Anything>
    AI-Competition-Collections <https://github.com/SWHL/AI-Competition-Collections/tree/main>
    SAHI: Slicing Aided Hyper Inference <https://github.com/obss/sahi>
    SAHI: A vision library for large-scale object detection & instance segmentation <https://medium.com/codable/sahi-a-vision-library-for-performing-sliced-inference-on-large-images-small-objects-c8b086af3b80>
    fine-tuning CLIP Model + Custom Pipeline for Image Similarity <https://www.width.ai/post/92-44-product-similarity-through-fine-tuning-clip-model-custom-pipeline-for-image-similarity>
    Google research <https://ai.googleblog.com/?m=1>
    OpenMMLabCamp è®­ç»ƒè¥<https://github.com/open-mmlab/OpenMMLabCamp/blob/main/README.md>
    coding-interview-university <https://github.com/jwasham/coding-interview-university/blob/main/translations/README-cn.md>
    Nvidia DeepLearningExamples <https://github.com/NVIDIA/DeepLearningExamples/tree/master>
    Pose estimation for AR and Robotics BOP: Benchmark for 6D Object Pose Estimation <https://bop.felk.cvut.cz/home/> 

Computer Vision
==================
.. toctree::
    Open-Vocabulary Semantic Segmentation with Mask-adapted CLIP <https://github.com/facebookresearch/ov-seg>
    DINOv2: State-of-the-art computer vision models with self-supervised learning <https://ai.facebook.com/blog/dino-v2-computer-vision-self-supervised-learning/>
    F-VLM: Open-Vocabulary Object Detection upon Frozen Vision and Language Models <https://github.com/google-research/google-research/blob/c31def47370fbdfa385275f150462b1dfaaadf1f/fvlm/README.md>
    Awesome-Open-Vocabulary-Object-Detection <https://github.com/YimingCuiCuiCui/awesome-open-vocabulary-object-detection>

Object Detection
==================

.. toctree::
    TAO Pretrained Object Detection <https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/models/pretrained_object_detection>
    slicing-aided-hyper-inference <https://learnopencv.com/slicing-aided-hyper-inference/>
    PaddleDetectionå®ç°äººæµé‡ç»Ÿè®¡äººä½“æ£€æµ‹ <https://blog.csdn.net/m0_63642362/article/details/121434604>
    FastViT: A Fast Hybrid Vision Transformer using Structural Reparameterization <https://arxiv.org/pdf/2303.14189.pdf>

Re-Identification
=================

.. toctree::
    

Action recognition
==================

.. toctree::
    CLIP æ¨¡å‹ <CLIPè®ºæ–‡.md>
    ActionCLIP <https://github.com/sallymmx/ActionCLIP>
    è§†é¢‘åŠ¨ä½œç†è§£å’Œåˆ†ç±» <Action_Classification.md>
    Nvidia Tao Toolkit <bodyposenet.md>
    LangChain <https://python.langchain.com/en/latest/modules/models/getting_started.html>
    Action-Recognition Application with NVIDIA TAO and DeepStream <https://www.youtube.com/watch?v=9cSyNtpIqLc>
    NGC ActionRecognitionNet Model Card <https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/models/actionrecognitionnet/version>
    Deepstream 3d Action recognition <https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_3D_Action.html>
    Temporal Segment Networks (TSN) <https://github.com/yjxiong/temporal-segment-networks>
    Action Recognition Model Zoo <https://github.com/open-mmlab/mmaction/blob/master/MODEL_ZOO.md>
    TAO ActionRecognitionNet <https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/resources/cv_samples/version/v1.4.1/files/action_recognition_net/actionrecognitionnet.ipynb>
    NVIDIA TAO Body Pose Estimation <https://docs.nvidia.com/tao/tao-toolkit/text/bodypose_estimation/bodyposenet.html>
    åŸºäºPaddleçš„æ™ºæ…§äº¤é€šé¢„æµ‹ç³»ç»Ÿ <https://aistudio.baidu.com/aistudio/projectdetail/4542547>
    deepstream-bodypose-3d <https://github.com/NVIDIA-AI-IOT/deepstream_reference_apps/tree/master/deepstream-bodypose-3d>

YOLO Series
============

.. toctree::
    JetsonYolov5 <https://github.com/mailrocketsystems/JetsonYolov5/tree/main>
    YOLOv8 on Jetson <https://github.com/triple-Mu/YOLOv8-TensorRT/blob/main/docs/Jetson.md>
    DeepStream-Yolo <https://github.com/marcoslucianops/DeepStream-Yolo>
    Ultralytics YOLOv8 <https://github.com/ultralytics/ultralytics/blob/a2bb42dfe96e39cd1513740236424b8ad61b5270/README.zh-CN.md>
    Ultralytics YOLOv8 Modes <https://docs.ultralytics.com/modes/>
    yolov7 <https://github.com/WongKinYiu/yolov7/tree/pose>
    yolov7-pose-e2e-trt <https://github.com/BaofengZan/yolov7-pose-e2e-trt>
    edgeai-yolov5 <https://github.com/TexasInstruments/edgeai-yolov5/tree/yolo-pose>
    yolov7-pose <https://github.com/nanmi/yolov7-pose>
    edgeyolo <https://github.com/LSH9832/edgeyolo>
    yolov7-pose-estimation <https://github.com/RizwanMunawar/yolov7-pose-estimation>


Segment
===============

.. toctree::
    NVIDA semantic-segmentation <https://github.com/NVIDIA/semantic-segmentation/tree/main>
    Segment Anything in High Quality <https://huggingface.co/spaces/sam-hq-team/sam-hq>
    huggingface/Segment-Anything-Video <https://huggingface.co/spaces/ArtGAN/Segment-Anything-Video>
    github/segment-anything-video <https://github.com/kadirnar/segment-anything-video>
    Prompt-Segment-Anything <https://github.com/RockeyCoss/Prompt-Segment-Anything/tree/master>
    huggingface/Prompt-Segment-Anything-Demo <https://huggingface.co/spaces/rockeycoss/Prompt-Segment-Anything-Demo>

LLM Zoo
===============

.. toctree::
    Chinese Large Language Model <chinese_large_language_model.md>
    LLM Zoo: democratizing ChatGPT <https://github.com/FreedomIntelligence/LLMZoo>
    FindTheChatGPTer GPT4å¼€æºâ€œå¹³æ›¿â€ <https://github.com/chenking2020/FindTheChatGPTer>
    Chinese-Vicuna llama+loraæ–¹æ¡ˆ <https://github.com/Facico/Chinese-Vicuna/blob/master/docs/readme-zh.md>
    langchain-ChatGLM  åŸºäºæœ¬åœ°çŸ¥è¯†åº“çš„ ChatGLM é—®ç­”<https://github.com/imClumsyPanda/langchain-ChatGLM>
    LangChain-ChatGLM-Webui <https://github.com/thomas-yanxin/LangChain-ChatGLM-Webui>
    GPT Academic <https://github.com/binary-husky/gpt_academic>
    Open LLM Leaderboard <https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard>
    MOSS æ¨¡å‹ <https://github.com/OpenLMLab/MOSS>
    LLaVA: Large Language and Vision Assistant <https://llava-vl.github.io>
    Docker Build ChatGLM-6B <docker_chatgml.md>
    ä¸­æ–‡å¤§æ¨¡å‹é›†åˆ <https://my.oschina.net/oscpyaqxylk/blog/8727824>
    LLM ï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰æ•´ç† <https://my.oschina.net/oscpyaqxylk/blog/8727824>
    Chinese-Vicuna <https://github.com/Facico/Chinese-Vicuna/tree/master>
    haotian-liu/LLaVA <https://github.com/haotian-liu/LLaVA>
    Chinese-LLaMA-Alpaca <https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/æ¨¡å‹æ¨ç†ä¸éƒ¨ç½²>
    llama-docker-playground <https://github.com/soulteary/llama-docker-playground>
    LLMsPracticalGuide  å¤§å‹è¯­è¨€æ¨¡å‹å®ç”¨æŒ‡å— <https://github.com/Mooler0410/LLMsPracticalGuide>
    Tuning LLMs <https://github.com/beyondguo/LLM-Tuning>
    ç™¾å·æ™ºèƒ½ Baichaun-7B, Baichuan2-7B <https://huggingface.co/baichuan-inc/Baichuan-7B>

Visual Language
===============

.. toctree::
    ViperGPT: Visual Inference via Python Execution for Reasoning <https://github.com/cvlab-columbia/viper>
    vision_language_pretraining.md <https://github.com/huggingface/blog/blob/7317911dac44caf135ff37615427f16040a86f40/vision_language_pretraining.md>
    GLIP Grounded Language-Image Pre-training <https://github.com/microsoft/GLIP>
    LLaVA: Large Language and Vision Assistant <https://llava-vl.github.io>

MultiModal Machine Learning
===========================
.. toctree::
    Multi-Source Data Fusion MDPI <https://www.mdpi.com/1424-8220/23/4/1823>

Paddle
============
.. toctree::
    PP-YOLOE-SOD å°ç›®æ ‡æ£€æµ‹æ¨¡å‹ <https://github.com/PaddlePaddle/PaddleDetection/blob/0128c6d6ef0c846bcbb272960d8b20d80948f3fa/configs/smalldet/README.md>
    è¾“ç”µé€šé“éšæ‚£ç›®æ ‡æ£€æµ‹ç®—æ³•baseline <https://aistudio.baidu.com/aistudio/projectdetail/6428247?forkThirdPart=1>
    paddledetection readthedocs <https://paddledetection.readthedocs.io/index.html>
    PaddleYOLO <https://github.com/PaddlePaddle/PaddleYOLO>
    FastDeploy deploy Jetson <https://aistudio.baidu.com/aistudio/projectdetail/4597810>

Text-to-Image Generation
========================
.. toctree::
    GLIGEN: Open-Set Grounded Text-to-Image Generation <https://gligen.github.io>
    stable-diffusion-webui <https://github.com/AUTOMATIC1111/stable-diffusion-webui>
    stable-diffusion-webui-docker <https://github.com/AbdBarho/stable-diffusion-webui-docker>

HuggingFace Model Card
======================
.. toctree::
    gpt4-x-alpaca-13b-native-4bit-128g-cuda <https://huggingface.co/4bit/gpt4-x-alpaca-13b-native-4bit-128g-cuda>
    Open LLM Leaderboard <https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard>
    liuhaotian/LLaVA-13b-delta-v0 <https://huggingface.co/liuhaotian/LLaVA-13b-delta-v0>
    microsoft/visual_chatgpt <https://huggingface.co/spaces/microsoft/visual_chatgpt>
    LLaVA: Large Language and Vision Assistant <https://llava.hliu.cc>
    Visual Instruction Tuning LLaVA: Large Language and Vision Assistant <https://llava-vl.github.io>

DataSet
===============

.. toctree::
    Waymo autonomous driving  <https://github.com/waymo-research/waymo-open-dataset>
    waymo challenges <https://waymo.com/open/challenges/>
    imagenet1000_clsidx_to_labels <https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a#file-imagenet1000_clsid_to_human-txt>
    ImageNet Object Localization Challenge 167.62 GB <https://www.kaggle.com/competitions/imagenet-object-localization-challenge/data>
    ä½¿ç”¨cocotoolsè¿›è¡ŒF1-Scoreè¯„ä¼° <cocotools_cal_f1_score.md>
    é‡å¤å›¾ç‰‡æ£€æµ‹ Meta sscd-copy-detection <https://github.com/facebookresearch/sscd-copy-detection>
    COCO JSON Format with supervision <https://roboflow.com/formats/coco-json>

NLP
=============

.. toctree::
    å›¾è§£Transformer <https://blog.csdn.net/longxinchen_ml/article/details/86533005>
    HanLP <https://hanlp.hankcs.com/docs/index.html>
    å…¨æ–‡ç´¢å¼• åˆ†è¯å’Œæœç´¢ <https://github.com/Kevin-wenyu/blog/blob/18abfa6b21b50682e663acd78ae45ce694be5c40/201611/20161115_01.md>
    Top-AI-Conferences-Paper-with-Code <https://github.com/MLNLP-World/Top-AI-Conferences-Paper-with-Code/tree/1d03a4fec72344192836f8f6d8c16310fd855b35>

Depth Estimationæ·±åº¦ä¼°è®¡
================================

.. toctree::
    depth estimation papers <https://github.com/ssssober/Depth-Estimation>
    Jetson Inference Depth <https://github.com/dusty-nv/jetson-inference/blob/master/docs/depthnet.md>

å¤©æ± æ¯”èµ›
================

.. toctree::
    â€œé˜¿é‡Œçµæ°â€é—®å¤©å¼•æ“ç”µå•†æœç´¢ç®—æ³•èµ› <https://tianchi.aliyun.com/competition/entrance/531946>
    E-commerce-Search-Recallç”µå•†æœç´¢å¬å›ç¬¬äºŒåæ–¹æ¡ˆ <https://github.com/muyuuuu/E-commerce-Search-Recall>
    [ç«èµ›] â€œé˜¿é‡Œçµæ°â€é—®å¤©å¼•æ“ç”µå•†æœç´¢ç®—æ³•èµ› ç¬¬äºŒå <https://zhuanlan.zhihu.com/p/533923570>
    â€œé˜¿é‡Œçµæ°â€é—®å¤©å¼•æ“ç”µå•†æœç´¢ç®—æ³•èµ› <https://github.com/zwkkk/wentian-rank2>
    Multi-CPR: A Multi Domain Chinese Dataset for Passage Retrieval <https://github.com/Alibaba-NLP/Multi-CPR>
    FT-Data Ranker: Fine-Tuning Data Processing Competition for LLMs <https://tianchi.aliyun.com/competition/entrance/532158/information>
    FT-Data Rankerï¼šå¤§è¯­è¨€æ¨¡å‹å¾®è°ƒæ•°æ®ç«èµ› -- 7Bæ¨¡å‹èµ›é“ <https://tianchi.aliyun.com/competition/entrance/532158?spm=a2c22.12281949.0.0.605a3b74C9kT9o>

ONNX
=================

.. toctree::
    A collection of pre-trained, state-of-the-art models in the ONNX format <https://github.com/onnx/models/tree/main>

Plate detection
=================

.. toctree::
    Sample app code for LPR deployment on DeepStream deepstream_lpr_app <https://github.com/NVIDIA-AI-IOT/deepstream_lpr_app>
    è½¦ç‰Œæ£€æµ‹ï¼ˆLPDNetï¼‰ Model Card <https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/models/lpdnet>
    License Plate Recognition (LPRNet) Model Card <https://registry.ngc.nvidia.com/orgs/nvidia/teams/tao/models/lprnet>
    Real-Time License Plate Detection and Recognition App <https://developer.nvidia.com/blog/creating-a-real-time-license-plate-detection-and-recognition-app>

Audio Detection
===============

.. toctree::
    éŸ³é¢‘æ ‡è®°çš„ä¸€è‡´ç»„åˆè’¸é¦ï¼ˆCEDï¼‰Consistent Ensemble Distillation for Audio Tagging (CED) <https://github.com/RicherMans/CED>
    Audio-Classification-Deep-Learning using ANN,CNN1D,CNN2D Kaggle Notebook <https://www.kaggle.com/code/abishekas11/audio-classification-using-deep-learning>
    Audio-Classification-Deep-Learning using ANN,CNN1D,CNN2D GitHub <https://github.com/abishek-as/Audio-Classification-Deep-Learning/tree/main>
    Audio Classification Using ANN UrbanSound8K <https://www.kaggle.com/code/endofnight17j03/f-audio-classification#Graph-Between-Loss-and-Val-Loss>
    Freesound Audio Tagging 2019 <https://www.kaggle.com/c/freesound-audio-tagging-2019>
    Alibaba-MIIL AudioClassfication <https://github.com/Alibaba-MIIL/AudioClassfication>
    Bird@Edge Bird Species Recognition at the Edge using NVIDIA Jetson Nano on the Eï¬€icientNet-B3 <https://github.com/umr-ds/BirdEdge/tree/main>
    BirdClef 2023: Pytorch Lightning-Inference <https://www.kaggle.com/code/nischaydnk/birdclef-2023-pytorch-lightning-inference>
    PANNs: Large-Scale Pretrained Audio Neural Networks for Audio Pattern Recognition <https://github.com/qiuqiangkong/audioset_tagging_cnn>
    Consistent Ensemble Distillation for Audio Tagging (CED) <https://github.com/RicherMans/CED>
    Pretrained CED on ğŸ¤— Hugging Face <https://github.com/jimbozhang/hf_transformers_custom_model_ced/tree/main>
    Audio Classification, Tagging & Sound Event Detection in PyTorch <https://github.com/sithu31296/audio-tagging?tab=readme-ov-file>
    audio label studio <https://labelstud.io/blog/understanding-audio-classification-everything-you-need-to-know/>
    freesound <https://freesound.org>
    An Introduction to Audio Classification with Keras <https://wandb.ai/mostafaibrahim17/ml-articles/reports/An-Introduction-to-Audio-Classification-with-Keras--Vmlldzo0MDQzNDUy>

SfM(Structure-from-Motion)
==========================
.. toctree::
    Image Matching Workshop <https://www.kaggle.com/competitions/image-matching-challenge-2023/discussion/417407>
    SuperPoint <https://arxiv.org/pdf/1712.07629.pdf>
    COLMAP - Structure-from-Motion and Multi-View Stereo <https://github.com/colmap/colmap>

3D Reconstruction
=================

.. toctree::
    NeuralRecon: Real-Time Coherent 3D Reconstruction from Monocular Video <https://zju3dv.github.io/neuralrecon/>